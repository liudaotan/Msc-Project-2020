{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "### Training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Data preprocessing [7 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_columns = np.array(df.columns)\n",
    "# replace ？ and ' ' as NaN\n",
    "for column in array_columns:\n",
    "    df[column] = df[column].apply(lambda x: np.NaN if (str(x).isspace() or (x == '?')) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent of Null in Blind_Make : 0.05 %\n",
      "The percent of Null in Blind_Model : 0.05 %\n",
      "The percent of Null in Blind_Submodel : 0.05 %\n",
      "The percent of Null in Cat1 : 0.16666666666666669 %\n",
      "The percent of Null in Cat2 : 35.30333333333333 %\n",
      "The percent of Null in Cat3 : 0.03666666666666667 %\n",
      "The percent of Null in Cat4 : 43.28333333333333 %\n",
      "The percent of Null in Cat5 : 43.32666666666667 %\n",
      "The percent of Null in Cat6 : 0.16666666666666669 %\n",
      "The percent of Null in Cat7 : 54.93333333333334 %\n",
      "The percent of Null in Cat8 : 0.006666666666666667 %\n",
      "The percent of Null in Cat10 : 0.03333333333333333 %\n",
      "The percent of Null in Cat11 : 0.19333333333333333 %\n",
      "The percent of Null in Cat12 : 0.17333333333333334 %\n",
      "The percent of Null in OrdCat : 0.06333333333333332 %\n"
     ]
    }
   ],
   "source": [
    "# calculate the proportion of NaN\n",
    "i = 0\n",
    "percent_of_null_list = np.array([])\n",
    "for column in np.array(df.columns):\n",
    "    df_null = df[df[column].isnull()]\n",
    "    percent_of_null = df_null.shape[0]/df.shape[0]\n",
    "    if percent_of_null != 0:\n",
    "        print('The percent of Null in',array_columns[i],':',percent_of_null*100 ,\"%\")\n",
    "    percent_of_null_list = np.append(percent_of_null_list,percent_of_null)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 33, 16, 34,  1,\n",
       "        2,  3,  4, 15, 17, 10,  5,  6,  7, 20,  8, 13, 19, 18,  9, 11, 12,\n",
       "       14], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the index \n",
    "index_of_sorted_Null = np.argsort(percent_of_null_list)\n",
    "index_of_sorted_Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the null rates of columns of 9 11 12 14 are very high, we drop these columns\n",
    "df = df.drop(['Cat2','Cat4','Cat5','Cat7'],axis =1)\n",
    "# ID、Calendar_Year、Blind_Make、Blind_Submodel,etc are not related to the target value\n",
    "df = df.drop(['Household_ID','Row_ID'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "# in the rest of the columns, the null rates are very low, we can regard the 'NaN' as an\n",
    "# attributes and replace the 'NaN' with '0'\n",
    "data = data.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Vehicle','Calendar_Year','Model_Year','Var1','Var2','Var3','Var4','Var5','Var6',\n",
    "           'Var7','Var8','NVVar1','NVVar2','NVVar3','NVVar4']:\n",
    "    data[col] = data[col].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Blind_Model','Blind_Submodel', 'Cat1', 'Cat3', 'Cat6', 'Cat8', 'Cat9', 'Cat10', 'Cat11', 'Cat12','NVCat']:\n",
    "    data[col] = data[col].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in data.csv into train_data and test_data before deal with the imblance.\n",
    "train_data,test_data = \\\n",
    "    train_test_split(data,test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list two lists of categorical_features and continuous_features\n",
    "categorical_features = list(data.columns[data.dtypes == 'object'])\n",
    "continuous_features = list(data.columns[data.dtypes == 'float64'])\n",
    "continuous_features = continuous_features[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# set a ColumnTransformer\n",
    "full_transform = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), continuous_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown = 'ignore'), categorical_features),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attributes = data.drop('Claim_Amount', axis=1)\n",
    "data_targets = data['Claim_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attributes_prepared = full_transform.fit_transform(data_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_attributes = train_data.drop('Claim_Amount', axis=1)\n",
    "train_data_targets = train_data['Claim_Amount']\n",
    "\n",
    "test_data_attributes = test_data.drop('Claim_Amount', axis=1)\n",
    "test_data_targets = test_data['Claim_Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with the imbalance of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero claim in train data:  17832\n",
      "Non zero claim in train data:  7668\n"
     ]
    }
   ],
   "source": [
    "num_zero_claim = (train_data_targets == 0).sum()\n",
    "num_not_zero_claim = (train_data_targets != 0).sum()\n",
    "print('Zero claim in train data: ',num_zero_claim)\n",
    "print('Non zero claim in train data: ',num_not_zero_claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use undersample to deal the imbalance\n",
    "# get the indexes of 0\n",
    "zero_claim_indices = np.array(train_data_targets[train_data_targets==0].index)\n",
    "# get the indexes of non 0\n",
    "not_zero_claim_indices = np.array(train_data_targets[train_data_targets!=0].index)\n",
    "# get the same number indexes with non 0 index from 0 index\n",
    "random_zero_claim_indices = np.random.choice(zero_claim_indices,num_not_zero_claim,replace = False)\n",
    "# merge the two indexes\n",
    "under_sample_indices = np.concatenate([random_zero_claim_indices,not_zero_claim_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_attributes_under_sample = train_data_attributes.loc[under_sample_indices,:]\n",
    "train_data_targets = train_data_targets.loc[under_sample_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conlumns tranformer \n",
    "train_data_attributes_under_sample_prepared = full_transform.transform(train_data_attributes_under_sample)\n",
    "test_data_attributes_prepared = full_transform.transform(test_data_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Performance using a single model [8 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=5,random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train_data_attributes_under_sample_prepared, train_data_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the performance\n",
    "linear_reg_predictions_on_X_val = lin_reg.predict(test_data_attributes_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression RMSE:  304.09815241610994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "error = np.sqrt(mean_squared_error(linear_reg_predictions_on_X_val, test_data_targets))\n",
    "print('Linear regression RMSE: ',error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge,RidgeCV\n",
    "ridge_reg = Ridge(alpha = 10)\n",
    "ridge_reg.fit(train_data_attributes_under_sample_prepared, train_data_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg_predictions_on_X_val = ridge_reg.predict(test_data_attributes_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression RMSE:  293.801252542613\n"
     ]
    }
   ],
   "source": [
    "error_ridge = np.sqrt(mean_squared_error(ridge_reg_predictions_on_X_val, test_data_targets))\n",
    "print('Ridge regression RMSE: ',error_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=5, random_state=1, test_size=None, train_size=None),\n",
       "             estimator=Ridge(),\n",
       "             param_grid={'alpha': array([ 0.1,  1. ,  5. , 10. ])})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Grid search to find the best parameters\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "alpha_opts = np.array([0.1,1,5,10])\n",
    "param_grid = dict(alpha = alpha_opts)\n",
    "grid = GridSearchCV(Ridge(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_data_attributes_under_sample_prepared, train_data_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rig_grid = Ridge(alpha = grid.best_params_[\"alpha\"])\n",
    "rig_grid.fit(train_data_attributes_under_sample_prepared, train_data_targets)\n",
    "ypred_rig_grid = rig_grid.predict(test_data_attributes_prepared)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression RMSE after Grid search :  293.801252542613\n"
     ]
    }
   ],
   "source": [
    "error_ridge_grid = np.sqrt(mean_squared_error(ypred_rig_grid, test_data_targets))\n",
    "print('Ridge regression RMSE after Grid search : ',error_ridge_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forests for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators = 50) \n",
    "\n",
    "rf.fit(train_data_attributes_under_sample_prepared, train_data_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_on_X_val = rf.predict(test_data_attributes_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rf = np.sqrt(mean_squared_error(rf_predictions_on_X_val, test_data_targets))\n",
    "print('Random forests regression RMSE : ',error_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Grid search\n",
    "# rf_param_grid = dict(n_estimators = [5,50,100],min_samples_split = [3,5,10])\n",
    "# rf_grid = GridSearchCV(RandomForestRegressor(), param_grid = rf_param_grid, cv = cv)\n",
    "# rf_grid.fit(train_data_attributes_under_sample_prepared, train_data_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_grid = RandomForestRegressor(n_estimators = rf_grid.best_params_[\"n_estimators\"],min_samples_split = rf_grid.best_params_[\"min_samples_split\"])\n",
    "# rf_grid.fit(train_data_attributes_under_sample_prepared, train_data_targets)\n",
    "# ypred_rf_grid = rf_grid.predict(test_data_attributes_prepared) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_rf_grid = np.sqrt(mean_squared_error(ypred_rf_grid, test_data_targets))\n",
    "# print('Random forests regression RMSE after Grid search: ',error_rf_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gradient tree boosting for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor(n_estimators= 3, max_depth = 3)\n",
    "gb.fit(train_data_attributes_under_sample_prepared, train_data_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_predictions_on_X_val = gb.predict(test_data_attributes_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_gb = np.sqrt(mean_squared_error(gb_predictions_on_X_val, test_data_targets))\n",
    "print('Gradient tree boosting for regression RMSE: ',error_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Grid search\n",
    "# n_estimators_opts = [3, 13, 50, 100]\n",
    "# max_depth_opts = [1,6,9,12]\n",
    "\n",
    "# gb_param_grid = dict(n_estimators = n_estimators_opts, max_depth = max_depth_opts)\n",
    "# gb_grid = GridSearchCV(GradientBoostingRegressor(), param_grid = gb_param_grid, cv = cv)\n",
    "# gb_grid.fit(train_data_attributes_under_sample_prepared, train_data_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb_grid = GradientBoostingRegressor(n_estimators = gb_grid.best_params_[\"n_estimators\"], max_depth = gb_grid.best_params_[\"max_depth\"])\n",
    "# gb_grid.fit(train_data_attributes_under_sample_prepared, train_data_targets)\n",
    "# ypred_gb_grid = gb_grid.predict(test_data_attributes_prepared) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# error_gb_grid = np.sqrt(mean_squared_error(ypred_gb_grid, test_data_targets))\n",
    "# print('Gradient tree boosting RMSE after Grid search: ',error_gb_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance using a combination of two models [6 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) binary classifier\n",
    "- random  forests  for classification\n",
    "- gradient boosting for classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forests for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform train_data_targets and test_data_targets to 0 1 \n",
    "train_data_targets_transformed = 1 * (train_data_targets != 0)\n",
    "test_data_targets_transformed = 1 * (test_data_targets != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(train_data_attributes_under_sample_prepared, train_data_targets_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predictions_on_X_val = rfc.predict(test_data_attributes_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_rfc = (rfc_predictions_on_X_val == test_data_targets_transformed).sum()/len(test_data_targets_transformed)\n",
    "print('Accuracy of RandomForestClassifier: ', Accuracy_rfc*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gradient boosting for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(train_data_attributes_under_sample_prepared, train_data_targets_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_predictions_on_X_val = gbc.predict(test_data_attributes_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_gbc = (gbc_predictions_on_X_val == test_data_targets_transformed).sum()/len(test_data_targets_transformed)\n",
    "print('Accuracy of GradientBoostingClassifier: ',Accuracy_gbc*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   b) If  the  claim  was  different  from  zero, train  a  regression model to predict the actual value of the claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_train_data_attributes_under_sample = train_data_attributes_under_sample[train_data_targets != 0]\n",
    "non_zero_train_data_targets = train_data_targets[train_data_targets != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_train_data_attributes_under_sample_prepared = full_transform.transform(non_zero_train_data_attributes_under_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "lin_reg_in_Q3b = LinearRegression()\n",
    "lin_reg_in_Q3b.fit(non_zero_train_data_attributes_under_sample_prepared, non_zero_train_data_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression\n",
    "ridge_reg_in_Q3b = Ridge(alpha = 10)\n",
    "ridge_reg_in_Q3b.fit(non_zero_train_data_attributes_under_sample_prepared, non_zero_train_data_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor\n",
    "rf_in_Q3b = RandomForestRegressor(n_estimators = 50)\n",
    "rf_in_Q3b.fit(non_zero_train_data_attributes_under_sample_prepared, non_zero_train_data_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient tree boosting for regression\n",
    "gb_in_Q3b = GradientBoostingRegressor(n_estimators= 3, max_depth = 3)\n",
    "gb_in_Q3b.fit(non_zero_train_data_attributes_under_sample_prepared, non_zero_train_data_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) tandem  model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two models\n",
    "def tandem_model(X_test, model1 = rfc , model2 = rf):\n",
    "    tandem_pridiction  = np.empty((X_test.shape[0],))\n",
    "    mask_of_not_zero = (model1.predict(X_test) != 0) \n",
    "    for i in range(len(gbc.predict(X_test))):\n",
    "        if mask_of_not_zero[i]:\n",
    "            tandem_pridiction[i] = model2.predict(X_test[i])\n",
    "        else:\n",
    "            tandem_pridiction[i] = 0\n",
    "    return tandem_pridiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model1 in [rfc,gbc]:\n",
    "    for model2 in [lin_reg_in_Q3b, ridge_reg_in_Q3b,rf_in_Q3b,gb_in_Q3b]:\n",
    "        prediction_tan = tandem_model(test_data_attributes_prepared, model1 = model1 , model2 = model2)\n",
    "        print(f'Prediction of {model1} and {model2}:')\n",
    "        print('RMSE:', np.sqrt(mean_squared_error(prediction_tan,test_data_targets)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Report the performance of the best models over the test set [2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# In step 2, the best model is the Gradient tree boosting model\n",
    "prediction_of_test_data_via_gb = gb.predict(test_data_attributes_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the performence\n",
    "test_error_on_gradientTree = np.sqrt(mean_squared_error(prediction_of_test_data_via_gb,test_data_targets))\n",
    "print('RMSE of Gradient tree: ',test_error_on_gradientTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In step 3, the best model is the tandem model based on GradientBoostingClassifier and GradientBoostingRegressor\n",
    "predictions_on_test = tandem_model(test_data_attributes_prepared,model1 = gbc, model2 = gb_in_Q3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the performence\n",
    "error_tandem = np.sqrt(mean_squared_error(predictions_on_test,test_data_targets))\n",
    "print('RMSE of tandem model: ',error_tandem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Present your solution [4 marks]\n",
    "Provide four interesting and meaningful observations/comments about your machine learning pipeline, with minimum three sentences for each observation/comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The missing value\n",
    "\n",
    "Due to various reasons, our original data is not complete, and the machine learning model cannot directly deal with the missing values, so it is necessary to deal with the missing values before fitting the data. There are many ways to deal with the missing values, each with advantages and disadvantages. In the training data involved in this question, there are four attributes whose missing values exceed 30%, so these four columns are directly discarded. And 0 is used to fill in the remaining missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data imbalance\n",
    "\n",
    "A data imbalance is an imbalance of the target data. If not preprocessed, the data fitting will not be good enough. The model will treat the claim amount of 0 as the norm and the fitted model will not perform well when dealing with non-0 data. Usually, there are two ways to deal with data imbalance: undersample and oversample. In this paper, the method of Undersample is adopted. The advantage of this method is that all data are real values, while the disadvantage is that all data sets cannot be fully utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. GridSearchCV\n",
    "\n",
    "Models for many regression and classification problems. When we don't know how the parameters of the model are set, we can use GridSearchCV to traverse the set of parameters we have given and filter out the best parameters from it. In most cases, results with GridSearchCV are better than results without GridSearchCV. It is worth noting that in the process the random forest, the number of decision trees is not as good as more, and the result will fluctuate up and down at a stable level as the number of trees reaches a certain value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Categorical attributes\n",
    "\n",
    "There are many categorical attributes in the data. The model cannot handle them directly, so it needs to transcode them into discrete encoding space that the model can handle. Onehotencoder is used to handle such data. Because there are many elements, a sparse matrix is formed which is much wider than the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.  Overfitting\n",
    "\n",
    "In this paper, RMSE values are used to measure the performance of the models. However, a low RMSE value not equal to a good predictor. For the GB model, although RMSE results are good, overfitting occurs. The GB model is very powerful and easy to be overfitted completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.  Create a function that contains the best model you built from Steps 1 to 4 that we will use to assess the performance of your design over an independent test set [3 marks]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_insurance_claim_predictor(Xtest):\n",
    "    Xtest = Xtest.drop(['Cat2','Cat4','Cat5','Cat7'],axis =1)\n",
    "    Xtest = Xtest.drop(['Household_ID','Row_ID'],axis =1)\n",
    "    Xtest=Xtest.replace(to_replace='?', value=np.nan)\n",
    "    Xtest = Xtest.fillna('0')\n",
    "    for col in ['Vehicle','Calendar_Year','Model_Year','Var1','Var2','Var3','Var4','Var5','Var6', 'Var7','Var8','NVVar1','NVVar2','NVVar3','NVVar4']:\n",
    "        Xtest[col] = Xtest[col].astype('float64')\n",
    "    for col in ['Blind_Model','Blind_Submodel', 'Cat1', 'Cat3', 'Cat6', 'Cat8', 'Cat9', 'Cat10', 'Cat11', 'Cat12','NVCat','OrdCat']:\n",
    "        Xtest[col] = Xtest[col].astype(object)\n",
    "    Xtest_temp = full_transform.transform(Xtest)\n",
    "    return gb.predict(Xtest_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = my_insurance_claim_predictor(Xtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
